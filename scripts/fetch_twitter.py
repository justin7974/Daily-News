#!/usr/bin/env python3
"""
Twitter KOL é¢„æŠ“å–è„šæœ¬
20 KOL å¹¶å‘æŠ“å–ï¼Œè¾“å‡º JSON

ç”¨æ³•:
  python3 fetch_twitter.py YYYY-MM-DD [--log]

æ—¶é—´çª—å£: å‰ä¸€å¤© 08:00 CST â†’ å½“å¤© 08:00 CST
è¾“å‡º: JSON åˆ° stdout
é€€å‡ºç : 0=æˆåŠŸ, 1=å‚æ•°é”™è¯¯, 2=ct0è¿‡æœŸ(403)
"""
import subprocess
import json
import sys
import os
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed

CST = timezone(timedelta(hours=8))


def parse_bird_date(date_str):
    """è§£æ bird CLI è¾“å‡ºçš„æ—¥æœŸï¼Œè¿”å› aware UTC datetime"""
    formats = [
        '%a %b %d %H:%M:%S %z %Y',   # Mon Feb 16 19:50:40 +0000 2026
        '%a, %d %b %Y %H:%M:%S %z',
        '%Y-%m-%dT%H:%M:%S%z',
        '%Y-%m-%dT%H:%M:%SZ',
    ]
    for fmt in formats:
        try:
            dt = datetime.strptime(date_str.strip(), fmt)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            else:
                dt = dt.astimezone(timezone.utc)
            return dt
        except (ValueError, OverflowError):
            continue
    return None


def fetch_user_tweets(handle, start_utc, end_utc):
    """ç”¨ bird CLI æŠ“å–å•ä¸ª KOL çš„æ¨æ–‡"""
    try:
        result = subprocess.run(
            ['bird', 'search', f'from:{handle}', '-n', '10', '--json'],
            capture_output=True, text=True, timeout=20
        )

        if result.returncode != 0:
            stderr = result.stderr.strip()
            if '403' in stderr or 'ct0' in stderr.lower():
                return [], 'ct0_expired'
            return [], f'error: {stderr[:100]}'

        tweets = []
        try:
            data = json.loads(result.stdout)
        except json.JSONDecodeError:
            # å°è¯• plain æ¨¡å¼è§£æ
            return fetch_user_tweets_plain(handle, start_utc, end_utc)

        if isinstance(data, list):
            for tweet in data:
                dt = None
                for date_field in ('createdAt', 'created_at', 'date', 'timestamp'):
                    if date_field in tweet:
                        dt = parse_bird_date(str(tweet[date_field]))
                        if dt:
                            break

                if not dt or not (start_utc <= dt < end_utc):
                    continue

                tweet_id = tweet.get('id') or tweet.get('tweet_id') or ''
                text = tweet.get('text') or tweet.get('full_text') or ''
                handle_from_tweet = tweet.get('author', {}).get('username', handle)
                is_reply = bool(tweet.get('inReplyToStatusId')
                                or tweet.get('in_reply_to_status_id')
                                or text.startswith('@'))

                tweets.append({
                    'handle': handle,
                    'text': text[:500],
                    'tweet_id': str(tweet_id),
                    'url': f"https://x.com/{handle}/status/{tweet_id}" if tweet_id else '',
                    'is_reply': is_reply,
                    'date': dt.strftime('%Y-%m-%d %H:%M UTC'),
                })
        return tweets, 'ok'
    except subprocess.TimeoutExpired:
        return [], 'timeout'
    except Exception as e:
        return [], str(e)[:100]


def fetch_user_tweets_plain(handle, start_utc, end_utc):
    """Fallback: ç”¨ bird plain æ¨¡å¼æŠ“å–"""
    try:
        result = subprocess.run(
            ['bird', 'search', f'from:{handle}', '-n', '10', '--plain'],
            capture_output=True, text=True, timeout=20
        )
        if result.returncode != 0:
            return [], f'plain_error: {result.stderr[:100]}'

        tweets = []
        current = {}
        for line in result.stdout.split('\n'):
            line = line.strip()
            if not line or line.startswith('â”€'):
                if current.get('text') and current.get('date'):
                    dt = parse_bird_date(current['date'])
                    if dt and start_utc <= dt < end_utc:
                        tweet_id = current.get('id', '')
                        is_reply = current.get('text', '').startswith('@')
                        tweets.append({
                            'handle': handle,
                            'text': current['text'][:500],
                            'tweet_id': str(tweet_id),
                            'url': current.get('url', ''),
                            'is_reply': is_reply,
                            'date': dt.strftime('%Y-%m-%d %H:%M UTC'),
                        })
                current = {}
                continue
            if line.startswith('date:'):
                current['date'] = line[5:].strip()
            elif line.startswith('url:'):
                current['url'] = line[4:].strip()
            elif line.startswith('id:'):
                current['id'] = line[3:].strip()
            elif not line.startswith('>') and not line.startswith('@'):
                current.setdefault('text', line)
        return tweets, 'ok'
    except Exception as e:
        return [], str(e)[:100]


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 fetch_twitter.py YYYY-MM-DD [--log]", file=sys.stderr)
        sys.exit(1)

    date_str = sys.argv[1]
    do_log = '--log' in sys.argv

    base_dir = "/Users/justin/Library/CloudStorage/Dropbox/CC/Projects/Daily News"
    kols_path = os.path.join(base_dir, "config/twitter_kols.json")
    log_dir = os.path.join(base_dir, "fetch_log")

    with open(kols_path) as f:
        kols_config = json.load(f)

    # æ”¶é›†æ‰€æœ‰ handle
    all_handles = []
    for group, handles in kols_config.get('groups', {}).items():
        for h in handles:
            if h not in all_handles:
                all_handles.append(h)

    # æ—¶é—´çª—å£: å‰ä¸€å¤© 08:00 CST â†’ å½“å¤© 08:00 CST
    # = å‰ä¸€å¤© 00:00 UTC â†’ å½“å¤© 00:00 UTC
    target = datetime.strptime(date_str, '%Y-%m-%d')
    start_utc = datetime(target.year, target.month, target.day, 0, 0, 0, tzinfo=timezone.utc) - timedelta(days=1)
    end_utc = datetime(target.year, target.month, target.day, 0, 0, 0, tzinfo=timezone.utc)

    print(f"ğŸ“… æ—¶é—´çª—å£ (UTC): {start_utc.strftime('%Y-%m-%d %H:%M')} â†’ {end_utc.strftime('%Y-%m-%d %H:%M')}", file=sys.stderr)
    print(f"ğŸ¦ æŠ“å– {len(all_handles)} ä¸ª KOL...", file=sys.stderr)

    # å¹¶å‘æŠ“å–
    all_tweets = []
    statuses = {}
    ct0_expired = False

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {
            executor.submit(fetch_user_tweets, h, start_utc, end_utc): h
            for h in all_handles
        }
        for future in as_completed(futures):
            handle = futures[future]
            tweets, status = future.result()
            statuses[handle] = {'count': len(tweets), 'status': status}
            all_tweets.extend(tweets)
            if status == 'ct0_expired':
                ct0_expired = True

    # ç»Ÿè®¡
    ok_count = sum(1 for s in statuses.values() if s['status'] == 'ok')
    original = sum(1 for t in all_tweets if not t.get('is_reply'))
    replies = sum(1 for t in all_tweets if t.get('is_reply'))

    print(f"âœ… {ok_count}/{len(all_handles)} KOL æˆåŠŸï¼Œ{len(all_tweets)} æ¡æ¨æ–‡ï¼ˆ{original} åŸåˆ› + {replies} å›å¤ï¼‰", file=sys.stderr)

    if ct0_expired:
        print("âš ï¸ ct0 è¿‡æœŸï¼éƒ¨åˆ† KOL è·å–å¤±è´¥ï¼ˆ403ï¼‰", file=sys.stderr)

    # è¾“å‡º JSON
    print(json.dumps(all_tweets, ensure_ascii=False, indent=2))

    # å†™æ—¥å¿—
    if do_log:
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, f"{date_str}-twitter.json")
        log_data = {
            'date': date_str,
            'window_utc': f"{start_utc.isoformat()} â†’ {end_utc.isoformat()}",
            'total_tweets': len(all_tweets),
            'original': original,
            'replies': replies,
            'kol_statuses': statuses,
        }
        with open(log_file, 'w') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ æ—¥å¿—å·²å†™å…¥ {log_file}", file=sys.stderr)

    # ct0 è¿‡æœŸæ—¶é€€å‡ºç  2
    if ct0_expired:
        sys.exit(2)


if __name__ == '__main__':
    main()
