#!/usr/bin/env python3
"""
ä¸ºç°æœ‰æ—¥æŠ¥æ·»åŠ Twitterå†…å®¹
"""
import subprocess
import json
import sys
from datetime import datetime, timedelta
import os
import re

def fetch_twitter_for_user(handle, target_date):
    start_time = target_date.replace(hour=8, minute=0, second=0, microsecond=0)
    end_time = start_time + timedelta(days=1)
    
    try:
        result = subprocess.run(['bird', 'search', f'from:{handle}', '-n', '5', '--plain'],
                              capture_output=True, text=True, timeout=15)
        if result.returncode != 0:
            return []
        
        tweets = []
        lines = result.stdout.split('\n')
        current = {}
        for line in lines:
            line = line.strip()
            if not line or line.startswith('â”€'):
                if current.get('text') and 'date' in current:
                    try:
                        dt = datetime.strptime(current['date'], '%a %b %d %H:%M:%S %z %Y')
                        dt = dt.replace(tzinfo=None)
                        if start_time <= dt < end_time:
                            tweets.append({
                                'handle': handle,
                                'text': current['text'][:350],
                                'url': current.get('url', ''),
                                'date': dt.strftime('%m-%d %H:%M')
                            })
                    except:
                        pass
                current = {}
                continue
            if line.startswith('date:'):
                current['date'] = line[5:].strip()
            elif line.startswith('url:'):
                current['url'] = line[4:].strip()
            elif line and not line.startswith('@') and not line.startswith('>'):
                current['text'] = line
        return tweets
    except:
        return []

def fetch_all_twitter(kols_config, target_date):
    with open(kols_config) as f:
        kols = json.load(f)
    
    all_handles = []
    for group, handles in kols.get('groups', {}).items():
        all_handles.extend(handles)
    
    all_tweets = []
    for handle in all_handles[:12]:  # é™åˆ¶æ•°é‡é¿å…å¤ªæ…¢
        tweets = fetch_twitter_for_user(handle, target_date)
        all_tweets.extend(tweets)
    
    return all_tweets

def add_twitter_to_markdown(file_path, tweets):
    with open(file_path, 'r') as f:
        content = f.read()
    
    # ç§»é™¤æ—§çš„Twitteréƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
    if '## Twitter KOL æ—¥æŠ¥' in content:
        content = content.split('## Twitter KOL æ—¥æŠ¥')[0].strip()
    
    # ç§»é™¤ç»“å°¾çš„Generated by
    content = re.sub(r'\*Generated by å°è™¾ ğŸ¦\*$', '', content).strip()
    
    lines = [content, '', '## Twitter KOL æ—¥æŠ¥', '']
    
    # åˆ†ç±»
    ai_handles = ['karpathy', 'emollick', 'Hesamation', 'vasuman', 'EXM7777', 'kloss_xyz', 'godofprompt', 'rryssf_', 'AmirMushich']
    startup_handles = ['gregisenberg', 'levelsio', 'marclou', 'MengTo', 'rileybrown', 'corbin_braun', 'jackfriks']
    
    ai_tweets = [t for t in tweets if t['handle'] in ai_handles][:5]
    startup_tweets = [t for t in tweets if t['handle'] in startup_handles][:5]
    insight_tweets = [t for t in tweets if t['handle'] not in ai_handles + startup_handles][:5]
    
    if ai_tweets:
        lines.extend(['### ğŸ§  AI æŠ€æœ¯å‰æ²¿', ''])
        for t in ai_tweets:
            lines.append(f"**@{t['handle']}** ({t.get('date', '')})")
            lines.append(f"> {t['text']}")
            if t.get('url'):
                lines.append(f"ğŸ”— {t['url']}")
            lines.append('')
    
    if startup_tweets:
        lines.extend(['### ğŸš€ åˆ›ä¸šåŠ¨æ€', ''])
        for t in startup_tweets:
            lines.append(f"**@{t['handle']}** ({t.get('date', '')})")
            lines.append(f"> {t['text']}")
            if t.get('url'):
                lines.append(f"ğŸ”— {t['url']}")
            lines.append('')
    
    if insight_tweets:
        lines.extend(['### ğŸ’¬ è§‚ç‚¹ä¸æ´å¯Ÿ', ''])
        for t in insight_tweets:
            lines.append(f"**@{t['handle']}** ({t.get('date', '')})")
            lines.append(f"> {t['text']}")
            if t.get('url'):
                lines.append(f"ğŸ”— {t['url']}")
            lines.append('')
    
    lines.append('*Generated by å°è™¾ ğŸ¦*')
    
    with open(file_path, 'w') as f:
        f.write('\n'.join(lines))

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("Usage: python3 add_twitter.py YYYY-MM-DD")
        sys.exit(1)
    
    date_str = sys.argv[1]
    target = datetime.strptime(date_str, '%Y-%m-%d')
    base = "/Users/justin/Library/CloudStorage/Dropbox/CC/Projects/Daily News"
    file_path = f"{base}/content/{date_str}.md"
    
    if not os.path.exists(file_path):
        print(f"âŒ File not found: {file_path}")
        sys.exit(1)
    
    print(f"ğŸ“… {date_str}: Fetching Twitter...", file=sys.stderr)
    tweets = fetch_all_twitter(f"{base}/config/twitter_kols.json", target)
    print(f"   {len(tweets)} tweets", file=sys.stderr)
    
    add_twitter_to_markdown(file_path, tweets)
    print(json.dumps({"date": date_str, "tweets": len(tweets)}))
