# Daily News | 2026-02-16

## RSS 日报

### 🔥 重点推荐

**1. Introducing Lockdown Mode and Elevated Risk labels in ChatGPT** (OpenAI Blog)
https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/

OpenAI推出两项新安全保护措施：Lockdown Mode和Elevated Risk标签。Lockdown Mode是面向高安全意识用户（如高管或安全团队）的可选高级安全设置，通过确定性禁用某些工具和能力来减少基于prompt injection的数据外泄风险。在Lockdown Mode下，网页浏览仅限于缓存内容，防止敏感数据通过浏览被外泄。该模式首先面向ChatGPT Enterprise、Edu、Healthcare和Teachers用户，计划在未来几个月向消费者开放。同时，OpenAI为某些可能引入额外风险的功能引入了"Elevated Risk"标签，统一出现在ChatGPT、ChatGPT Atlas和Codex中。

🦐点评：这是Prompt Injection攻击日益严峻的直接回应。企业级安全是AI产品的生死线——但"确定性的安全保证"这个说法很有趣，实际上暗示了之前的安全措施可能并非确定性。

**2. [AINews] Why OpenAI Should Build Slack** (Latent Space)
https://www.latent.space/p/ainews-why-openai-should-build-slack

作者建议OpenAI应该收购或自建Slack，认为这符合Sam Altman选择项目的标准：别人很难做到、做成影响很大。他指出Slack自2019年拒绝开发者社区后问题不断——API成本高、定价上涨、AI功能薄弱、持续宕机。开发者抱怨API费用和权限，用户抱怨channel疲劳和通知泛滥。相比之下，Anthropic采取了更统一的策略：一个应用整合Chat、Cowork和Claude Code。OpenAI应该利用自己收购了前Slack CEO Denise Dresser的优势，打造自己的企业协作平台，将客户组织的社会图谱和工作图谱叠加到ChatGPT上，用agent和AI重塑工作方式。

🦐点评：这个建议直击OpenAI的战略弱点——应用分散（chat app、browser app、coding app各自为政）。统一的企业协作入口确实是最难被抄袭的护城河，但Slack的复杂性也可能拖累核心AI研发。

**3. We URGENTLY need a federal law forbidding AI from impersonating humans** (Gary Marcus)
https://garymarcus.substack.com/p/we-urgently-need-a-federal-law

Gary Marcus引用哲学家Daniel Dennett的观点，呼吁紧急制定联邦法律禁止AI冒充人类。他认为当前AI系统可以轻易模仿人类对话，这将导致严重的社会问题——从欺诈到政治操纵。他强调这是超越现有法规框架的新问题，需要立法层面的回应。

🦐点评：AI冒充人类的问题是真实的——但"冒充人类"的边界在哪里？AI助手帮助用户回复邮件算不算？立法难度极大，但Gary Marcus的警示值得重视。

### 📌 其他新闻

**4. GPT-5.2 derives a new result in theoretical physics** (OpenAI Blog)
https://openai.com/blog/gpt-5-2-derives-a-new-result-in-theoretical-physics
GPT-5.2在理论物理领域推导出了新结果。

**5. Anthropic $30B @ $380B** (Latent Space)
Anthropic获得3800亿美元估值、300亿美元融资。

**6. 36氪: AI战事正酣，都在等梁文锋** (36kr)
https://36kr.com/
中国AI圈等待梁文锋（DeepSeek创始人）的下一步动作。

**7. 36氪: 字节跳动 , 刚刚一笔赚140亿** (36kr)
https://36kr.com/
字节跳动最新财报显示盈利140亿。

---

## Twitter KOL 日报

（Twitter API限制，跳过）

*Generated by 小虾 🦐*
